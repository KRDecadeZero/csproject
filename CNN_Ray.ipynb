{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is cuda!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from livelossplot import PlotLosses\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "import os\n",
    "import tempfile\n",
    "import ray\n",
    "from ray import tune, air\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from functools import partial\n",
    "from ray.train import Checkpoint\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"Device is {device}!\")\n",
    "\n",
    "local_dir = os.path.abspath(\"./ray_tune\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dns_qtype</th>\n",
       "      <th>dns_rcode</th>\n",
       "      <th>dns_query</th>\n",
       "      <th>dst_ip_bytes</th>\n",
       "      <th>src_pkts</th>\n",
       "      <th>label</th>\n",
       "      <th>type</th>\n",
       "      <th>conn_state-OTH</th>\n",
       "      <th>conn_state-REJ</th>\n",
       "      <th>conn_state-RSTO</th>\n",
       "      <th>...</th>\n",
       "      <th>service-ssl</th>\n",
       "      <th>dns_AA--1</th>\n",
       "      <th>dns_AA-F</th>\n",
       "      <th>dns_AA-T</th>\n",
       "      <th>dns_RA--1</th>\n",
       "      <th>dns_RA-F</th>\n",
       "      <th>dns_RA-T</th>\n",
       "      <th>dns_RD--1</th>\n",
       "      <th>dns_RD-F</th>\n",
       "      <th>dns_RD-T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3786</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>4765</td>\n",
       "      <td>172</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>6112</td>\n",
       "      <td>800</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>5259</td>\n",
       "      <td>525</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>2790</td>\n",
       "      <td>408</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46559</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12284</td>\n",
       "      <td>158</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46560</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8462</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>ddos</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46561</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>3631</td>\n",
       "      <td>375</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46562</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>9338</td>\n",
       "      <td>712</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46563</th>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>6528</td>\n",
       "      <td>349</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46564 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       dns_qtype  dns_rcode  dns_query  dst_ip_bytes  src_pkts  label    type  \\\n",
       "0              0          0          2          3786         6      0  normal   \n",
       "1             12          0       4765           172         1      0  normal   \n",
       "2             12          3       6112           800         1      0  normal   \n",
       "3             43          0       5259           525         1      0  normal   \n",
       "4             43          0       2790           408         1      0  normal   \n",
       "...          ...        ...        ...           ...       ...    ...     ...   \n",
       "46559          1          0      12284           158         1      0  normal   \n",
       "46560          0          0          2          8462        10      1    ddos   \n",
       "46561         12          0       3631           375         1      0  normal   \n",
       "46562         28          0       9338           712         1      0  normal   \n",
       "46563         12          3       6528           349         2      0  normal   \n",
       "\n",
       "       conn_state-OTH  conn_state-REJ  conn_state-RSTO  ...  service-ssl  \\\n",
       "0                   0               0                0  ...            0   \n",
       "1                   0               0                0  ...            0   \n",
       "2                   0               0                0  ...            0   \n",
       "3                   0               0                0  ...            0   \n",
       "4                   0               0                0  ...            0   \n",
       "...               ...             ...              ...  ...          ...   \n",
       "46559               0               0                0  ...            0   \n",
       "46560               0               0                0  ...            1   \n",
       "46561               0               0                0  ...            0   \n",
       "46562               0               0                0  ...            0   \n",
       "46563               0               0                0  ...            0   \n",
       "\n",
       "       dns_AA--1  dns_AA-F  dns_AA-T  dns_RA--1  dns_RA-F  dns_RA-T  \\\n",
       "0              1         0         0          1         0         0   \n",
       "1              0         0         1          0         0         1   \n",
       "2              0         1         0          0         1         0   \n",
       "3              0         1         0          0         1         0   \n",
       "4              0         1         0          0         1         0   \n",
       "...          ...       ...       ...        ...       ...       ...   \n",
       "46559          0         0         1          0         1         0   \n",
       "46560          1         0         0          1         0         0   \n",
       "46561          0         1         0          0         1         0   \n",
       "46562          0         1         0          0         1         0   \n",
       "46563          0         1         0          0         1         0   \n",
       "\n",
       "       dns_RD--1  dns_RD-F  dns_RD-T  \n",
       "0              1         0         0  \n",
       "1              0         1         0  \n",
       "2              0         1         0  \n",
       "3              0         1         0  \n",
       "4              0         1         0  \n",
       "...          ...       ...       ...  \n",
       "46559          0         1         0  \n",
       "46560          1         0         0  \n",
       "46561          0         1         0  \n",
       "46562          0         1         0  \n",
       "46563          0         0         1  \n",
       "\n",
       "[46564 rows x 45 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./preprocessed.csv', low_memory=False) \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dns_qtype</th>\n",
       "      <th>dns_rcode</th>\n",
       "      <th>dns_query</th>\n",
       "      <th>dst_ip_bytes</th>\n",
       "      <th>src_pkts</th>\n",
       "      <th>conn_state-OTH</th>\n",
       "      <th>conn_state-REJ</th>\n",
       "      <th>conn_state-RSTO</th>\n",
       "      <th>conn_state-RSTOS0</th>\n",
       "      <th>conn_state-RSTR</th>\n",
       "      <th>...</th>\n",
       "      <th>service-ssl</th>\n",
       "      <th>dns_AA--1</th>\n",
       "      <th>dns_AA-F</th>\n",
       "      <th>dns_AA-T</th>\n",
       "      <th>dns_RA--1</th>\n",
       "      <th>dns_RA-F</th>\n",
       "      <th>dns_RA-T</th>\n",
       "      <th>dns_RD--1</th>\n",
       "      <th>dns_RD-F</th>\n",
       "      <th>dns_RD-T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3786</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>4765</td>\n",
       "      <td>172</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>6112</td>\n",
       "      <td>800</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>5259</td>\n",
       "      <td>525</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>2790</td>\n",
       "      <td>408</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   dns_qtype  dns_rcode  dns_query  dst_ip_bytes  src_pkts  conn_state-OTH  \\\n",
       "0          0          0          2          3786         6               0   \n",
       "1         12          0       4765           172         1               0   \n",
       "2         12          3       6112           800         1               0   \n",
       "3         43          0       5259           525         1               0   \n",
       "4         43          0       2790           408         1               0   \n",
       "\n",
       "   conn_state-REJ  conn_state-RSTO  conn_state-RSTOS0  conn_state-RSTR  ...  \\\n",
       "0               0                0                  0                0  ...   \n",
       "1               0                0                  0                0  ...   \n",
       "2               0                0                  0                0  ...   \n",
       "3               0                0                  0                0  ...   \n",
       "4               0                0                  0                0  ...   \n",
       "\n",
       "   service-ssl  dns_AA--1  dns_AA-F  dns_AA-T  dns_RA--1  dns_RA-F  dns_RA-T  \\\n",
       "0            0          1         0         0          1         0         0   \n",
       "1            0          0         0         1          0         0         1   \n",
       "2            0          0         1         0          0         1         0   \n",
       "3            0          0         1         0          0         1         0   \n",
       "4            0          0         1         0          0         1         0   \n",
       "\n",
       "   dns_RD--1  dns_RD-F  dns_RD-T  \n",
       "0          1         0         0  \n",
       "1          0         1         0  \n",
       "2          0         1         0  \n",
       "3          0         1         0  \n",
       "4          0         1         0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(['label','type'], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label\n",
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.filter(items=['label'])\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.336797</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.432005</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.371713</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.197201</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1         2         3         4    5    6    7    8    9   ...  \\\n",
       "0  0.000000  0.0  0.000141  0.000044  0.000024  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "1  0.047059  0.0  0.336797  0.000002  0.000004  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "2  0.047059  0.6  0.432005  0.000009  0.000004  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "3  0.168627  0.0  0.371713  0.000006  0.000004  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "4  0.168627  0.0  0.197201  0.000005  0.000004  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "\n",
       "    33   34   35   36   37   38   39   40   41   42  \n",
       "0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  0.0  \n",
       "2  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  \n",
       "3  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  \n",
       "4  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max_scaler = MinMaxScaler()\n",
    "X =  pd.DataFrame(min_max_scaler.fit_transform(X))\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor(X.values) \n",
    "gt = torch.Tensor(y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([46564, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([46564, 1, 43])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.unsqueeze(1)\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.manual_seed(42)\n",
    "\n",
    "# Create a TensorDataset from your data and labels\n",
    "dataset = TensorDataset(x, gt)\n",
    "\n",
    "# Calculate the number of samples for training and testing datasets\n",
    "num_samples = len(dataset)\n",
    "train_size = int(num_samples * 0.7)\n",
    "test_size = num_samples - train_size\n",
    "\n",
    "def load_data():\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv(nn.Module):\n",
    "    def __init__(self, l1=100, l2=128, l3=256):\n",
    "        super(Conv, self).__init__()\n",
    "        self.l1 = nn.Conv1d(1, l1, 4,2,1)\n",
    "        self.b1 = nn.BatchNorm1d(l1)\n",
    "        self.l2 = nn.Conv1d(l1, l2, 4,2,1)\n",
    "        self.b2 = nn.BatchNorm1d(l2)\n",
    "        self.l3 = nn.Conv1d(l2, l3, 4,2,1)\n",
    "        self.b3 = nn.BatchNorm1d(l3)\n",
    "        self.last = nn.Linear(5 * l3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.b1(self.l1(x)))\n",
    "        x = torch.relu(self.b2(self.l2(x)))\n",
    "        x = torch.relu(self.b3(self.l3(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return torch.sigmoid(self.last(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cnn(config):\n",
    "    net = Conv(config[\"l1\"], config[\"l2\"], config[\"l3\"]).to(device)\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=config[\"lr\"])\n",
    "\n",
    "    if \"restore\" in config:\n",
    "        checkpoint_path = config[\"restore\"]\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        net.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "\n",
    "    trainset, _ = load_data()\n",
    "\n",
    "    test_abs = int(len(trainset) * 0.7)\n",
    "    train_subset, val_subset = torch.utils.data.random_split(\n",
    "        trainset, [test_abs, len(trainset) - test_abs])\n",
    "    \n",
    "    # Create DataLoaders\n",
    "    trainloader = DataLoader(train_subset, batch_size=int(config[\"batch_size\"]), shuffle=True, num_workers=0)\n",
    "    valloader = DataLoader(val_subset, batch_size=int(config[\"batch_size\"]), shuffle=True, num_workers=0)\n",
    "\n",
    "    for epoch in range(100):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        epoch_steps = 0\n",
    "        for i, data in enumerate(trainloader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            epoch_steps += 1\n",
    "\n",
    "        val_loss = 0.0\n",
    "        val_steps = 0\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        for i, data in enumerate(valloader, 0):\n",
    "            with torch.no_grad():\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = net(inputs)\n",
    "                preds = outputs.round()\n",
    "                total_correct += preds.eq(labels).sum().item()\n",
    "                total_samples += labels.size(0)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.cpu().numpy()\n",
    "                val_steps += 1\n",
    "\n",
    "        # Calculate overall validation accuracy\n",
    "        accuracy = (total_correct / total_samples) * 100\n",
    "                \n",
    "        with tempfile.TemporaryDirectory() as temp_checkpoint_dir:\n",
    "            checkpoint_path = os.path.join(temp_checkpoint_dir, \"checkpoint.pt\")\n",
    "            torch.save({\n",
    "                \"model_state_dict\": net.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            }, checkpoint_path)\n",
    "\n",
    "            # Use ray.train.report to report metrics and checkpoint\n",
    "            ray.train.report({\n",
    "                \"loss\": val_loss,\n",
    "                \"accuracy\": accuracy\n",
    "            }, checkpoint=Checkpoint.from_directory(temp_checkpoint_dir))\n",
    "    \n",
    "    print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_best_model(best_result):\n",
    "    best_trained_model = Conv(best_result.config[\"l1\"], best_result.config[\"l2\"], best_result.config[\"l3\"]).to(device)\n",
    "    \n",
    "    print(f'> Number of parameters {len(torch.nn.utils.parameters_to_vector(best_trained_model.parameters()))}')\n",
    "\n",
    "    checkpoint_path = os.path.join(best_result.checkpoint.to_directory(), \"checkpoint.pt\")\n",
    "\n",
    "    # Load the checkpoint\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    best_trained_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    _, testset = load_data()\n",
    "    \n",
    "    testloader = DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = best_trained_model(inputs)\n",
    "            predicted = outputs.round()\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Best trial test set accuracy: {accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-02-22 18:26:46</td></tr>\n",
       "<tr><td>Running for: </td><td>00:07:43.49        </td></tr>\n",
       "<tr><td>Memory:      </td><td>133.2/1132.4 GiB   </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=10<br>Bracket: Iter 64.000: -4.292829640209675 | Iter 32.000: -4.35857068374753 | Iter 16.000: -4.5591114312410355 | Iter 8.000: -4.582780361175537 | Iter 4.000: -4.772209011018276 | Iter 2.000: -4.8439407125115395 | Iter 1.000: -10.824007127434015<br>Logical resource usage: 64.0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_cnn_daf12_00000</td><td>TERMINATED</td><td>10.234.204.81:153689</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">4.0823e-05 </td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">      165.17    </td><td style=\"text-align: right;\">16.4853 </td><td style=\"text-align: right;\">   94.7541</td></tr>\n",
       "<tr><td>train_cnn_daf12_00001</td><td>TERMINATED</td><td>10.234.204.81:153689</td><td style=\"text-align: right;\">        1024</td><td style=\"text-align: right;\">0.0148224  </td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       68.9668  </td><td style=\"text-align: right;\"> 1.18125</td><td style=\"text-align: right;\">   94.6723</td></tr>\n",
       "<tr><td>train_cnn_daf12_00002</td><td>TERMINATED</td><td>10.234.204.81:153689</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">0.00156034 </td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       88.1763  </td><td style=\"text-align: right;\"> 8.5147 </td><td style=\"text-align: right;\">   94.4064</td></tr>\n",
       "<tr><td>train_cnn_daf12_00003</td><td>TERMINATED</td><td>10.234.204.81:153689</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">0.0962377  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.17108 </td><td style=\"text-align: right;\">10.0209 </td><td style=\"text-align: right;\">   93.3122</td></tr>\n",
       "<tr><td>train_cnn_daf12_00004</td><td>TERMINATED</td><td>10.234.204.81:153689</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">1.63041e-05</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.08031 </td><td style=\"text-align: right;\">20.0512 </td><td style=\"text-align: right;\">   92.3612</td></tr>\n",
       "<tr><td>train_cnn_daf12_00005</td><td>TERMINATED</td><td>10.234.204.81:153689</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">0.00816946 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.58311 </td><td style=\"text-align: right;\">18.6837 </td><td style=\"text-align: right;\">   94.1303</td></tr>\n",
       "<tr><td>train_cnn_daf12_00006</td><td>TERMINATED</td><td>10.234.204.81:153689</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">0.0805523  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.729688</td><td style=\"text-align: right;\">32.802  </td><td style=\"text-align: right;\">   94.1201</td></tr>\n",
       "<tr><td>train_cnn_daf12_00007</td><td>TERMINATED</td><td>10.234.204.81:153689</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">0.00100384 </td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       68.7785  </td><td style=\"text-align: right;\"> 4.28114</td><td style=\"text-align: right;\">   94.5904</td></tr>\n",
       "<tr><td>train_cnn_daf12_00008</td><td>TERMINATED</td><td>10.234.204.81:153689</td><td style=\"text-align: right;\">        1024</td><td style=\"text-align: right;\">0.0340293  </td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       49.4224  </td><td style=\"text-align: right;\"> 1.12535</td><td style=\"text-align: right;\">   94.2939</td></tr>\n",
       "<tr><td>train_cnn_daf12_00009</td><td>TERMINATED</td><td>10.234.204.81:153689</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">6.5426e-05 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.975827</td><td style=\"text-align: right;\">11.6271 </td><td style=\"text-align: right;\">   93.7621</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-22 18:19:11,268\tWARNING worker.py:2065 -- Warning: The actor ImplicitFunc is very large (15 MiB). Check that its definition is not implicitly capturing a large array or other object in scope. Tip: use ray.put() to put large objects in the Ray object store.\n",
      "2024-02-22 18:26:46,227\tINFO tune.py:1154 -- Total run time: 464.34 seconds (463.46 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config: {'l1': 8, 'l2': 32, 'l3': 128, 'lr': 0.03402934428936064, 'batch_size': 1024}\n",
      "Best trial final validation loss: 1.125353716313839\n",
      "Best trial final validation accuracy: 94.29389508129665\n",
      "> Number of parameters 18585\n",
      "Best trial test set accuracy: 94.32355046528275%\n"
     ]
    }
   ],
   "source": [
    "def main(num_samples=10, max_num_epochs=100, gpus_per_trial=1):\n",
    "    config = {\n",
    "        \"l1\": tune.sample_from(lambda _: 2 ** np.random.randint(3, 10)),\n",
    "        \"l2\": tune.sample_from(lambda _: 2 ** np.random.randint(3, 10)),\n",
    "        \"l3\": tune.sample_from(lambda _: 2 ** np.random.randint(3, 10)),\n",
    "        \"lr\": tune.loguniform(1e-5, 1e-1),\n",
    "        \"batch_size\": tune.choice([64, 128, 256, 512, 1024]),\n",
    "    }\n",
    "    scheduler = ASHAScheduler(\n",
    "        max_t=max_num_epochs,\n",
    "        grace_period=1,\n",
    "        reduction_factor=2)\n",
    "    \n",
    "    ray.shutdown()\n",
    "    ray.init(log_to_driver=False)\n",
    "    \n",
    "    tuner = tune.Tuner(\n",
    "        tune.with_resources(\n",
    "            tune.with_parameters(train_cnn),\n",
    "            resources={\"cpu\": 64, \"gpu\": gpus_per_trial}\n",
    "        ),\n",
    "        tune_config=tune.TuneConfig(\n",
    "            metric=\"loss\",\n",
    "            mode=\"min\",\n",
    "            scheduler=scheduler,\n",
    "            num_samples=num_samples,\n",
    "        ),\n",
    "        param_space=config,\n",
    "        run_config=air.RunConfig(\n",
    "            local_dir=local_dir,\n",
    "            name=\"cnn\",\n",
    "        )\n",
    "    )\n",
    "    results = tuner.fit()\n",
    "    \n",
    "    best_result = results.get_best_result(\"loss\", \"min\")\n",
    "\n",
    "    print(\"Best trial config: {}\".format(best_result.config))\n",
    "    print(\"Best trial final validation loss: {}\".format(\n",
    "        best_result.metrics[\"loss\"]))\n",
    "    print(\"Best trial final validation accuracy: {}\".format(\n",
    "        best_result.metrics[\"accuracy\"]))\n",
    "\n",
    "    test_best_model(best_result)\n",
    "\n",
    "main(num_samples=10, max_num_epochs=100, gpus_per_trial=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.filter(items=['type'])\n",
    "y['type'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/tghv73/myjupyterenv/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "y_int = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor(X.values) \n",
    "gt = torch.Tensor(y_int).long()\n",
    "x = x.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.manual_seed(42)\n",
    "\n",
    "# Create a TensorDataset from your data and labels\n",
    "dataset = TensorDataset(x, gt)\n",
    "\n",
    "# Calculate the number of samples for training and testing datasets\n",
    "num_samples = len(dataset)\n",
    "train_size = int(num_samples * 0.7)\n",
    "test_size = num_samples - train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv(nn.Module):\n",
    "    def __init__(self, l1=100, l2=128, l3=256):\n",
    "        super(Conv, self).__init__()\n",
    "        self.l1 = nn.Conv1d(1, l1, 4,2,1)\n",
    "        self.b1 = nn.BatchNorm1d(l1)\n",
    "        self.l2 = nn.Conv1d(l1, l2, 4,2,1)\n",
    "        self.b2 = nn.BatchNorm1d(l2)\n",
    "        self.l3 = nn.Conv1d(l2, l3, 4,2,1)\n",
    "        self.b3 = nn.BatchNorm1d(l3)\n",
    "        self.last = nn.Linear(5 * l3, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.b1(self.l1(x)))\n",
    "        x = torch.relu(self.b2(self.l2(x)))\n",
    "        x = torch.relu(self.b3(self.l3(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return torch.log_softmax(self.last(x), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cnn(config):\n",
    "    net = Conv(config[\"l1\"], config[\"l2\"], config[\"l3\"]).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=config[\"lr\"])\n",
    "\n",
    "    if \"restore\" in config:\n",
    "        checkpoint_path = config[\"restore\"]\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        net.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "\n",
    "    trainset, _ = load_data()\n",
    "\n",
    "    test_abs = int(len(trainset) * 0.7)\n",
    "    train_subset, val_subset = torch.utils.data.random_split(\n",
    "        trainset, [test_abs, len(trainset) - test_abs])\n",
    "    \n",
    "    # Create DataLoaders\n",
    "    trainloader = DataLoader(train_subset, batch_size=int(config[\"batch_size\"]), shuffle=True, num_workers=0)\n",
    "    valloader = DataLoader(val_subset, batch_size=int(config[\"batch_size\"]), shuffle=True, num_workers=0)\n",
    "\n",
    "    for epoch in range(100):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        epoch_steps = 0\n",
    "        for i, data in enumerate(trainloader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            epoch_steps += 1\n",
    "\n",
    "        val_loss = 0.0\n",
    "        val_steps = 0\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        for i, data in enumerate(valloader, 0):\n",
    "            with torch.no_grad():\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = net(inputs)\n",
    "                _, argmax = torch.max(outputs, dim=1)\n",
    "                total_correct += argmax.eq(labels).sum().item()\n",
    "                total_samples += labels.size(0)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.cpu().numpy()\n",
    "                val_steps += 1\n",
    "\n",
    "        # Calculate overall validation accuracy\n",
    "        accuracy = (total_correct / total_samples) * 100\n",
    "                \n",
    "        with tempfile.TemporaryDirectory() as temp_checkpoint_dir:\n",
    "            checkpoint_path = os.path.join(temp_checkpoint_dir, \"checkpoint.pt\")\n",
    "            torch.save({\n",
    "                \"model_state_dict\": net.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            }, checkpoint_path)\n",
    "\n",
    "            # Use ray.train.report to report metrics and checkpoint\n",
    "            ray.train.report({\n",
    "                \"loss\": val_loss,\n",
    "                \"accuracy\": accuracy\n",
    "            }, checkpoint=Checkpoint.from_directory(temp_checkpoint_dir))\n",
    "    \n",
    "    print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_best_model(best_result):\n",
    "    best_trained_model = Conv(best_result.config[\"l1\"], best_result.config[\"l2\"], best_result.config[\"l3\"]).to(device)\n",
    "    \n",
    "    print(f'> Number of parameters {len(torch.nn.utils.parameters_to_vector(best_trained_model.parameters()))}')\n",
    "\n",
    "    checkpoint_path = os.path.join(best_result.checkpoint.to_directory(), \"checkpoint.pt\")\n",
    "\n",
    "    # Load the checkpoint\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    best_trained_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    _, testset = load_data()\n",
    "    \n",
    "    testloader = DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = best_trained_model(inputs)\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Best trial test set accuracy: {accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-03-04 22:42:50</td></tr>\n",
       "<tr><td>Running for: </td><td>00:05:05.62        </td></tr>\n",
       "<tr><td>Memory:      </td><td>53.2/1132.4 GiB    </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=20<br>Bracket: Iter 64.000: -4.552404016256332 | Iter 32.000: -4.602373018860817 | Iter 16.000: -4.552751034498215 | Iter 8.000: -4.526329942047596 | Iter 4.000: -4.648592069745064 | Iter 2.000: -4.978965237736702 | Iter 1.000: -15.457783058285713<br>Logical resource usage: 64.0/64 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>status    </th><th>loc                  </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_cnn_d1852_00000</td><td>TERMINATED</td><td>10.234.204.79:3198685</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">0.0930954  </td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       54.8982  </td><td style=\"text-align: right;\"> 8.9823 </td><td style=\"text-align: right;\">   92.4634</td></tr>\n",
       "<tr><td>train_cnn_d1852_00001</td><td>TERMINATED</td><td>10.234.204.79:3198685</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">0.000617918</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.634857</td><td style=\"text-align: right;\">13.6499 </td><td style=\"text-align: right;\">   91.4613</td></tr>\n",
       "<tr><td>train_cnn_d1852_00002</td><td>TERMINATED</td><td>10.234.204.79:3198685</td><td style=\"text-align: right;\">         512</td><td style=\"text-align: right;\">0.000635583</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       59.798   </td><td style=\"text-align: right;\"> 4.51804</td><td style=\"text-align: right;\">   92.5862</td></tr>\n",
       "<tr><td>train_cnn_d1852_00003</td><td>TERMINATED</td><td>10.234.204.79:3198685</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">0.000798475</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.19681 </td><td style=\"text-align: right;\">39.9377 </td><td style=\"text-align: right;\">   92.218 </td></tr>\n",
       "<tr><td>train_cnn_d1852_00004</td><td>TERMINATED</td><td>10.234.204.79:3198685</td><td style=\"text-align: right;\">         512</td><td style=\"text-align: right;\">0.000773783</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       43.3463  </td><td style=\"text-align: right;\"> 4.82585</td><td style=\"text-align: right;\">   92.218 </td></tr>\n",
       "<tr><td>train_cnn_d1852_00005</td><td>TERMINATED</td><td>10.234.204.79:3198685</td><td style=\"text-align: right;\">        1024</td><td style=\"text-align: right;\">0.0471084  </td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       34.3187  </td><td style=\"text-align: right;\"> 2.33769</td><td style=\"text-align: right;\">   92.3305</td></tr>\n",
       "<tr><td>train_cnn_d1852_00006</td><td>TERMINATED</td><td>10.234.204.79:3198685</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">3.78511e-05</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.774884</td><td style=\"text-align: right;\">25.1312 </td><td style=\"text-align: right;\">   91.4715</td></tr>\n",
       "<tr><td>train_cnn_d1852_00007</td><td>TERMINATED</td><td>10.234.204.79:3198685</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">1.30376e-05</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.529261</td><td style=\"text-align: right;\">77.016  </td><td style=\"text-align: right;\">   60.8242</td></tr>\n",
       "<tr><td>train_cnn_d1852_00008</td><td>TERMINATED</td><td>10.234.204.79:3198685</td><td style=\"text-align: right;\">        1024</td><td style=\"text-align: right;\">5.33025e-05</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.307447</td><td style=\"text-align: right;\">21.3011 </td><td style=\"text-align: right;\">   12.6393</td></tr>\n",
       "<tr><td>train_cnn_d1852_00009</td><td>TERMINATED</td><td>10.234.204.79:3198685</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">1.07497e-05</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.26884 </td><td style=\"text-align: right;\">57.2941 </td><td style=\"text-align: right;\">   90.2955</td></tr>\n",
       "<tr><td>train_cnn_d1852_00010</td><td>TERMINATED</td><td>10.234.204.79:3198685</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">0.00415619 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.723849</td><td style=\"text-align: right;\">18.7411 </td><td style=\"text-align: right;\">   92.1873</td></tr>\n",
       "<tr><td>train_cnn_d1852_00011</td><td>TERMINATED</td><td>10.234.204.79:3198685</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">0.00963031 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.677491</td><td style=\"text-align: right;\">19.706  </td><td style=\"text-align: right;\">   92.0544</td></tr>\n",
       "<tr><td>train_cnn_d1852_00012</td><td>TERMINATED</td><td>10.234.204.79:3198685</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">0.00592616 </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        1.45336 </td><td style=\"text-align: right;\">10.1237 </td><td style=\"text-align: right;\">   91.5124</td></tr>\n",
       "<tr><td>train_cnn_d1852_00013</td><td>TERMINATED</td><td>10.234.204.79:3198685</td><td style=\"text-align: right;\">         512</td><td style=\"text-align: right;\">0.019891   </td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       34.6037  </td><td style=\"text-align: right;\"> 4.3074 </td><td style=\"text-align: right;\">   92.5555</td></tr>\n",
       "<tr><td>train_cnn_d1852_00014</td><td>TERMINATED</td><td>10.234.204.79:3198685</td><td style=\"text-align: right;\">        1024</td><td style=\"text-align: right;\">0.0108289  </td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       52.246   </td><td style=\"text-align: right;\"> 2.33932</td><td style=\"text-align: right;\">   92.7191</td></tr>\n",
       "<tr><td>train_cnn_d1852_00015</td><td>TERMINATED</td><td>10.234.204.79:3198685</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">4.96847e-05</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.559955</td><td style=\"text-align: right;\">17.2657 </td><td style=\"text-align: right;\">   91.1341</td></tr>\n",
       "<tr><td>train_cnn_d1852_00016</td><td>TERMINATED</td><td>10.234.204.79:3198685</td><td style=\"text-align: right;\">         512</td><td style=\"text-align: right;\">0.0543854  </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        0.746723</td><td style=\"text-align: right;\"> 5.33264</td><td style=\"text-align: right;\">   91.7476</td></tr>\n",
       "<tr><td>train_cnn_d1852_00017</td><td>TERMINATED</td><td>10.234.204.79:3198685</td><td style=\"text-align: right;\">         128</td><td style=\"text-align: right;\">0.00106179 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.823359</td><td style=\"text-align: right;\">20.2022 </td><td style=\"text-align: right;\">   91.993 </td></tr>\n",
       "<tr><td>train_cnn_d1852_00018</td><td>TERMINATED</td><td>10.234.204.79:3198685</td><td style=\"text-align: right;\">         256</td><td style=\"text-align: right;\">0.0055399  </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        0.941508</td><td style=\"text-align: right;\">10.1535 </td><td style=\"text-align: right;\">   91.5533</td></tr>\n",
       "<tr><td>train_cnn_d1852_00019</td><td>TERMINATED</td><td>10.234.204.79:3198685</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">0.00809672 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.29807 </td><td style=\"text-align: right;\">38.2626 </td><td style=\"text-align: right;\">   92.2385</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-04 22:37:48,913\tWARNING worker.py:2065 -- Warning: The actor ImplicitFunc is very large (16 MiB). Check that its definition is not implicitly capturing a large array or other object in scope. Tip: use ray.put() to put large objects in the Ray object store.\n",
      "2024-03-04 22:42:50,452\tINFO tune.py:1154 -- Total run time: 306.00 seconds (305.60 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config: {'l1': 8, 'l2': 8, 'l3': 512, 'lr': 0.047108434441103186, 'batch_size': 1024}\n",
      "Best trial final validation loss: 2.3376873284578323\n",
      "Best trial final validation accuracy: 92.33050414152775\n",
      "> Number of parameters 43866\n",
      "Best trial test set accuracy: 92.41231209735147%\n"
     ]
    }
   ],
   "source": [
    "def main(num_samples=10, max_num_epochs=100, gpus_per_trial=1):\n",
    "    config = {\n",
    "        \"l1\": tune.sample_from(lambda _: 2 ** np.random.randint(3, 10)),\n",
    "        \"l2\": tune.sample_from(lambda _: 2 ** np.random.randint(3, 10)),\n",
    "        \"l3\": tune.sample_from(lambda _: 2 ** np.random.randint(3, 10)),\n",
    "        \"lr\": tune.loguniform(1e-5, 1e-1),\n",
    "        \"batch_size\": tune.choice([64, 128, 256, 512, 1024]),\n",
    "    }\n",
    "    scheduler = ASHAScheduler(\n",
    "        max_t=max_num_epochs,\n",
    "        grace_period=1,\n",
    "        reduction_factor=2)\n",
    "    \n",
    "    ray.shutdown()\n",
    "    ray.init(log_to_driver=False)\n",
    "    \n",
    "    tuner = tune.Tuner(\n",
    "        tune.with_resources(\n",
    "            tune.with_parameters(train_cnn),\n",
    "            resources={\"cpu\": 64, \"gpu\": gpus_per_trial}\n",
    "        ),\n",
    "        tune_config=tune.TuneConfig(\n",
    "            metric=\"loss\",\n",
    "            mode=\"min\",\n",
    "            scheduler=scheduler,\n",
    "            num_samples=num_samples,\n",
    "        ),\n",
    "        param_space=config,\n",
    "        run_config=air.RunConfig(\n",
    "            local_dir=local_dir,\n",
    "            name=\"cnn\",\n",
    "        )\n",
    "    )\n",
    "    results = tuner.fit()\n",
    "    \n",
    "    best_result = results.get_best_result(\"loss\", \"min\")\n",
    "\n",
    "    print(\"Best trial config: {}\".format(best_result.config))\n",
    "    print(\"Best trial final validation loss: {}\".format(\n",
    "        best_result.metrics[\"loss\"]))\n",
    "    print(\"Best trial final validation accuracy: {}\".format(\n",
    "        best_result.metrics[\"accuracy\"]))\n",
    "\n",
    "    test_best_model(best_result)\n",
    "\n",
    "main(num_samples=20, max_num_epochs=100, gpus_per_trial=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mykernel",
   "language": "python",
   "name": "mykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
